Criar modelos mais complexos:
	+ Viterbi decoder (só usar o do CRF)
	+ CRF (só empilhar nos já existentes)
	+ Attention (só empilhar nos já existentes)
	Transformer (só empilhar nos já existentes)

Adicionar regularização:
	Dropout depois de quais camadas? (ablation)
	LayerNormalization depois de quais camadas? (ablation)
	l1 l2? (l1 = sparsity -> adicionar nn.l1loss aos parametros
			l2 = weight decay.
			focar em l2)

Testar com diferentes word embeddings (ablation):
	- polyglot
	- word2vec
	- fasttext
	- glove
	- fonseca

Adicionar word embeddings do ELMO:
	- dividir modelos em: base, body, head

Adicionar BPE vocab (não tem bons resultados pra PoS tagging):
https://pdfs.semanticscholar.org/87b8/60da2501169aafafdfa0cac18e6779a198c1.pdf

